\chapter{Analyze}\label{Chap:Analyze}
Das folgende Kapitel soll sich nun mit der Analyze des in Kap~\ref{Chap:Tracer} erstellten 
Trace befassen. Sie befasst sich dabei mit der erkennung potentieller Deadlocks 
durch die vorkommenden Mutexe und Routinen. \extend{Mehr zur Einführung}

\section{Deadlock durch Mutext}\label{Chan:Analyze-Sec:Mutex}
\draft{Deadlock Mutex Draft}
Als erstes sollen Deadlocks betrachtet werden, welche nur von (RW-)Mutexen erzeugt werden.
Dabei wird vor allem zyklischen Locking betrachtet, bei dem sich mehrere Routinen 
gegenseitig blockieren. 
Abb.~\ref{Chap:Analyze-Sec:Mutex-Fig:Zyclic} zeigt ein Beispiel, in welchem es zu zyklischem 
Locking kommen kann.
\begin{figure}[h!]
  \lstinputlisting{code/04-analyzer/zyclic-locking-example.txt}
  \caption{Beispielprogramm zyklisches Locking}
  \label{Chap:Analyze-Sec:Mutex-Fig:Zyclic}
\end{figure}
Routine 0 und Routine 1 können dabei gleichzeitig ausgeführt werden. Man betrachte den Fall, in dem 
Zeile 7 und 14 gleichzeitig ausgeführt werden, also Lock \texttt{y} von Routine 0 und Lock \texttt{x} 
von Routine 1 gehalten wird. In diesem Fall kann in keiner der Routinen die nächste Zeile augeführt werden,
da das jeweilige Locks, welches beansprucht werden soll bereits durch die andere Routine gehalten wird. 
Da sich diese Situation auch nicht von alleine auflößen kann, blockiert dass Programm, befindet sich also 
in einem zyklischen Deadlock.\\\\
Da solche Situtationen nur in ganz besonderen Situation auftreten (in dem obigen Beispiel müssen Zeilen 
7 und 14 genau gleichzeitig ausgeführt werden, ohne dass Zeile 8 oder 15 ausgeführt werden), muss 
ein Detektor, welcher vor solchen Situationen warnen soll, nicht nur tatsächliche Deadlocks, sondern
vor allem potenzielle, also nicht tatsächlich aufgetretene Deadlocks erkenne. Die Erkennung der 
potenziellen Deadlocks basiert hierbei auf iGoodLock~\cite{iGoodLock} und UNDEAD~\cite{Undead}. Dabei wird ein Lockgraph 
aufgebaut. Dieser Speichert die in dem Programm vorkommenden Knoten, sowie ihre Abhängigkeiten. 
Dies bedeutet, dass die Knoten des Graphen gerade die (RW-)Locks representieren. Es gibt dabei 
genau dann eine Kante von Knoten \texttt{x} nach \texttt{y}, wenn das Lock \texttt{y} beansprucht 
wird, während das Lock \texttt{x} gerade von der selben Routine gehalten wird. Eine 
genauere Erklärung der Implemenierung des Locks findet sich in~\cite{bachelor-project}. \todo{ist des erlabut, oder soll ich es nochmal komplett beschreiben}  \\\\
Der Graph wird basierend auf dem zufgezeichneten Trace aufgebaut. Dazu werden die Traces der 
einzelnen Routinen nacheinander durchlaufen. Für jede Routine erzeugen wir eine Liste \texttt{currentLocks} aller 
Locks, die momentan von der Routine gehalten werden. Die einzelnen Elemente des Trace einer 
Routine werden nun durchlaufen. Handelt es sich dabei um ein Lock Event eines Locks \texttt{x}, wird 
für jedes Lock \texttt{l} in \texttt{currentLocks} eine Kante von \texttt{l} nach \texttt{x} in den 
Lock-Graphen eingefügt. Anschließend wird \texttt{x} in \texttt{currentLocks} eingefügt.
Ist das handelt es sich bei dem Element um ein unlock Event auf dem Lock \texttt{x}, dann wird das 
letzt vorkommen von \texttt{x} auf \texttt{currentLocks} entfernt.\\
Nachdem der Trace einer Routine durchlaufen wurde, wird überprüft ob sich noch Elemente in 
\texttt{currentLocks} befinden. Ist dies der Fall, handelt es sich um Locks, welche zum Zeitpunkt der Terminierung 
des Programms noch nicht wieder freigegeben worden sind. Dies deutet darauf hin, dass die
entsprechende Routine nicht beendet wurde, z.B. weil das Programm bzw. die Main-Routine beendet wurden.
Dies kann einfach durch die entsprechende Logik des Programms zustande gekommen sein, es kann aber auch 
auf einen tatsächlich auftretenden Deadlock, z.B. durch doppeltes Locking des selben Locks in einer Routine, ohne dass 
es zwischenzeitlich wieder freigegeben wurde. In diesem Fall wird eine warnung ausgegeben.\\
Ein potenzieller Deadlock gibt sich nun, wenn in diesem Graph ein Kreis existert. Dabei muss darauf 
geachtet werden, dass nicht alle Kanten durch die selbe Routine erzeugt wurden, und dass in 
zwei, in dem Kreis hintereinander folgende Kanten der gemeinsame Knoten nicht beides mal durch eine 
R-Lock Operation durch Kanten verbunden wurde. Die Erkennung solcher Zyklen geschieht nun durch 
eine Tiefensuche auf dem erzeugen Baum. Wird ein solcher Zyklus erkannt, wird ebenfalls eine 
Warnung ausgegeben.


\section{Deadlock durch Channels}\label{Chap:Analyse-Sec:Channel}
Im folgenden sollen Deadlocks betrachtet werden, welche durch die Verwendung von Channels entstehen. Dabei sollen verschiedene 
Szenarien betrachtet werden, die auf das Auftreten von Deadlocks hindeuten können. \todo{Betrachtete Szenatien beschreiben}
\todo{Einschrenkungen beschreiben, z.B. nur unbuffered channels} \todo{select}

\subsection{Hängende ungepufferte Channel-Operationen}\label{Chap:Analyze-Sec:Channel-SubSec:Dangling}
Man betrachte das Programm in Abb.~\ref{Chap:Analyze-Sec:Channel-SubSec:Dangling-Fig:ExDangling}.
\begin{figure}[h!]
  \lstinputlisting{code/04-analyzer/example-dangling-channel.txt}
  \caption{Beispielprogramm mit hängendem Channel}
  \label{Chap:Analyze-Sec:Channel-SubSec:Dangling-Fig:ExDangling}
\end{figure}
Es gibt in diesem zwei mögliche Ausführungspfade. Man betrachtet zuerst den Fall, in dem 1 mit 3 synchronisiert. 
Da eine go-Routine automatisch abgebrochen wird,  
wenn die Main-Routine terminiert, entsteht hierbei kein Deadlock. Anders ist es, wenn 1 mit 2 synchronisiert. 
In diesem Fall wird die Main-Routine blockiert, ohne dass es eine Möglichkeit gibt, dass sie sich wieder 
befreit. Es kann also, abhängig davon, ob 1 oder 2 die Nachricht erhält zu einem Deadlock kommen. Was 
allerdings beide Fälle gemeinsam haben ist, dass sie eine Channel-Operation besitzen, welche zwar 
gestartet, allerdings nie ausgeführt wird.
In diesen Fällen gibt es in dem Trace eine Channel-Information, 
welche ein Pre- aber kein Post-Event besitzt. Solch eine Situation bezeichnen wir als hängenden Channel. 
Durch eine einfache traversierung des Traces können solche Situationen erkannt werden. Solche hängenden 
Channel können auf einen potenziellen oder tatsächlich auftretenden Channel hindeuten.
Es sei allerdings dazu gesagt, dass eine solche hängende Operation nicht immer zu einem Deadlock führen muss.
Man betrachte dazu das Beispiel in Abb.~\ref{Chap:Analyze-Sec:Channel-SubSec:Dangling-Fig:ExDanglingWithout}.
\begin{figure}[h!]
  \lstinputlisting{code/04-analyzer/example-dangling-without.txt}
  \caption{Hängender Channel ohne Deadlock}
  \label{Chap:Analyze-Sec:Channel-SubSec:Dangling-Fig:ExDanglingWithout}
\end{figure}
Da auf dem Channel \texttt{x} nie gesendet wird, kommtes es in Zeile~3 zu einer hängenden Channel-Operation. Da 
dabei aber die Main-Routine nicht blockiert wird, kommt es nicht zu einem Deadlock und die Go-Routine 
terminiert, sobald die Main-Routine terminiert. Solch eine Routine bezeichnen wir als leakende Routine.
Sie führt hierbei nicht zu einem Deadlock, ist aber in der Regel dennoch eine ungewollte Situation.
Es ist also sinnvoll, auch solche Situationen zu erkennen.\\\\
Wir sind nun also in der Lage solche Situationen zu erkennen. Um solche Situationen verhindern 
zu können, kann es aber auch sinnvoll sein für Channels, bei welchen eine solche Sitation aufgetreten ist 
alle potenziellen Kommunikationspartner anzugeben, um dem Nutzer bei der Suche und Beseitigung 
solcher Situationen zu helfen. Für Abb.~\ref{Chap:Analyze-Sec:Channel-SubSec:Dangling-Fig:ExDangling}
soll also angegeben werden können, dass die Send-Operation in 1 sowohl mit 2 als auch mit 3 
synchronisieren kann. Dabei sei allerdings zu beachten, dass nur weil eine Send- und eine 
Receive-Operation auf dem selben Channel und in unterschiedlichen Routine geschehen, nicht 
in jedem Fall eine Kommunikation zwischen diesen möglich ist. Man betrachte dazu das Beispiel in 
Abb.~\ref{Chap:Analyze-Sec:Channel-SubSec:Dangling-Fig:NoSync}.
% \begin{figure}[h!]
%   % \lstinputlisting{code/04-analyzer/example-no-sync.txt}
%   \caption{Beispielprogramm für unmögliche Synchronisation}
%   \label{Chap:Analyze-Sec:Channel-SubSec:Dangling-Fig:NoSync}
% \end{figure}
\todo{bild aktivieren wenn synchronisiert}
Auf dem Channel \texttt{x} wird in 1 gesendet und kann in 2 und 3 empfangen werden. Da es zwei Receive, 
aber nur eine Send-Operation gibt, kommt es zu einem hängenden Channel. Betrachtet man nur 
Channel \texttt{x} könnte man davon ausgehen, dass 1 nach 2 senden kann, was zu einem Deadlock
führen würde. Dies ist aber nicht möglich. Da der Channel \texttt{y} in 1 nach \texttt{x} sendet, 
in 2 allerdings von \texttt{x} empfangen muss, ist eine synchronisierung auf \texttt{x} von 1 nach 
2 nicht möglich und die beiden Operationen bilden demnach keine möglichen Kommunikationspartner.\\\\
Um mögliche Kommunikationspartner zu erkennen, nicht mögliche Kommunikationspartner wie in 
Abb~\ref{Chap:Analyze-Sec:Channel-SubSec:Dangling-Fig:NoSync} aber auszuschließen, werden
Vector-Clocks verwendet. Die grundlegende Idee basiert auf~\cite{PPDP18}.\\
In einem ersten Durchlauf wird dabei der Trace mit Vector-Clock Informationen nach der Methode 
von Fidge~\cite{Fidge} erweitert. Dazu werden alle Elemente des Trace in der Reihenfolge durchlaufen, 
in denen sie in den Trace eingefügt wurden. Die korrekte Reihenfolge zwischen den Traces ist dabei 
durch die Speicherung eines globalen Timers in den Elementen des Trace gegeben. Für jede Routine 
wird eine Vector-Clock gespeichter, welche für jede Routine einen Wert enthält. Zu Begin werden 
all diese Werte auf 0 gesetzt. Bei jedem Post-Event, sowohl für Send als auch Receive und für 
Signal und Wait Elemente wird der Wert der eigenen Routine in der lokalen Vector-Clock um eins 
erhöht. Bei einem Post-Receive und einem Wait Element wird die Vectorclock $vc'$ betrachtet, 
welche in der sendenden Routine zum Zeitpunkt des Post-Send- bzw. Signal-Elements vorlag. 
Da ein Send- bzw. Signal-Event immer vor dem Receive- bzw. Wait-Element erzeugt wird, wurde 
die entsprechende Vectorclock in jedem Fall bereits bestimmt. Die Zuordnung der Trace-Elemente 
ist möglich, da der globale Counter bei einem Send an den Empfangenden Channel mitgesendet 
wird, und in dem entsprechenden Post-Receive- bzw. Wait-Trace-Element gespeichert wird.
Bei einem Select-Statement wird nur derjenoge Fall betrachtet, der auch tatsächlich ausgeführt wurde.
Diese Vector-Clock \texttt{vc}
wird nun mit der lokalen Vector-Clock $vc$ der empfangenden Routine, bzw. der Wait-Routine 
\texttt{q} verrechnet und ersätzt diese. Dabei gilt\\
\begin{figure}[h]
  \centering
  % \lstinputlisting[frame=none, numbers=none]{code/04-analyzer/vector-clock.txt}
\end{figure}\todo{Code aktivieren wenn synchronisiert}\\
wobei $n$ die Anzahl der Routinen ist.\\
Für alle andern Elemente, z.B. Pre usw. wird einfach die lokale Vector-Clock der Routine übernommen, 
ohne diese zu veränden. Da nun die Vector-Clocks zu jedem Zeitpunk bestimmt wurde, kann jedem 
Send- und Receive-Trace-Element eine Pre- und eine Post-Vector-Clock zugeordnet werden. 
Dabei handelt es sich um die Vector-Clocks, die bei Erzeugung des Pre- bzw. Post-Events in 
der Routine, in der die Operation ausgeführ wurde vorlag. Für hängende Operationen, 
bei denen kein Post-Element existiert, werden alle Werte der Post-Vector-Clock auf 
max(Int32) gesetzt.
Man betrachte das Beispiel in Abb.~\ref{Chap:Analyze-Sec:Channel-SubSec:Dangling-Fig:PorgVC}.
\begin{figure}[h!]
  \centering
  % \lstinputlisting{code/04-analyzer/example-vector-clock-prog.txt}
  \caption{Beispielprogramm für die Betrachtung der Vector-Clocks}
  \label{Chap:Analyze-Sec:Channel-SubSec:Dangling-Fig:PorgVC}
\end{figure}
\todo{Bild aktivieren wenn synchronisiert}
Man betrachte den Fall, in dem 3 mit 4 und dann 1 mit 5 synchronisiert und 2 eine hängende Operation bildet.
In diesem Fall erhält man folgenden Trace:
\begin{align*}
  [&[signal(1, 2), signale(2, 3), pre(1, x?), post(7, 1, x?, 6), pre(8, x?), post(13, 1, x?, 11)]\\
  &[wait(9, 2), pre(10, x!), post(11, 1, x!), pre(12, 1?)]\\
  &[wait(4, 3), pre(5, 1!), post(6, 2, 1!),]
  ]
\end{align*}
Aus diesem Trace lassen sich nun die Vector-Clocks für die einzelnen Operationen berechnen.
Diese werden im Folgenden in der Form $^{vc}a^{vc'}$ mit der Pre-Vector-Clock $vc$ und der 
Post-Vector-Clock $vc'$ und der Channel-Operation $a$. Sie geben sich also als
\begin{align*}
  [&[^{[2,0,0]}x?^{[3,0,2]}, ^{[3,0,2]}x?^{[4,2,2]}]\\
  &[^{[1, 1, 0]}x!^{[1, 2, 0]}, ^{[1, 2, 0]}x?^{[max, max, max]}]\\
  &[^{[2, 0, 1]}x!^{[2, 0, 2]}]]
\end{align*}
Man bezeichne zwei Vector-Clocks $vc$ und $vc'$ als vergleichbar, wenn
$\forall i: vc[i] \leq vc'[i]$ oder $\forall i: vc[i] \geq vc'[i]$. Man 
schreibe in diesem Fall $vc \leq vc$ bzw. $vc \geq vc$ bzw.~allgemein 
$vc \gtreqless vc'$. Andernfalls 
bezeichnen man $vc$ und $vc'$ als unvergleichbar $vc \not\gtreqless vc'$. 
Sind zwei Vector-Clocks 
unvergleichbar, sind sie unabhängig und können somit gleichzeitig auftreten. 
Man erkennt also zwei Operationen, welche eine mögliche Kommunikation durchführen 
können daran, dass sie auf dem selben Channel definiert sind, eine Send-
und eine Receive-Operation definieren und dass 
entweder ihre Pre- oder Vector-Clock (oder beide) unvergleichbar sind.
Um alternative Kommunikationspartner für hängende Kanäle zu finden, werden also
die Pre- und Post-Vector-Clocks der Channels mit dem selben Channel verglichen.\\
Man betrachte die hängende Receive-Operation in dem obigen Beispiel. Es gibt 
in dem Programm 2 Send-Operationen, welche als Kommunikationspartner für 
die hängende Operation $r$ in frage kommen. Vergleicht man die Vector-Clocks der 
Send-Operationen mit denen der hängenden Operation wird aber klar, dass nur 
eine der beiden Operationen tatsächlich möglich ist. Für die Send-Operation 
in der 2. Routine (der selben wie die hängende Operation) $s_1$ gilt 
$s_{1, pre} \leq r_{pre}$ und $s_{1, post} \leq r_{pre}$.  
Für die andere Send-Operation $s_2$ in Routine 3 hingegen gilt 
$s_{1, pre} \not\gtreqless r_{pre}$. Sie kann also gleichzeitig mit der 
hängenden Operation ausgeführt werden und bildet somit einen potenziellen 
Kommunikation. Hierbei wird auch klar, warum es nicht nur ausreicht einen 
Trace aufzuzeichnen, wenn eine Operation ausgeführt wird. Da für die 
Post-Vector-Clocks gilt, dass $s_{2, post} \geq r_{post}$, kann allein aus der 
Post-Vector-Clock nicht auf eine mögliche Kommunikation geschlossen werden.
\todo{Besser beschreiben}

\subsection{Gepufferte Kanäle}\label{Chan:Analyze-Sec:Channel-SubSec:Buffered}
Anders als in ungepufferten Kanälen müssen in gepufferten Kanälen Send und 
Receive einer Nachricht nicht gleichzeitig ablaufen. Hierbei kann es 
zu Situationen kommen, in dem eine Nachricht zwar erfolgreich gesendet, aber
nie ausgelesen wird. Man betrachte dazu das Beispiel in 
Abb.~\ref{Chap:Analyze-Sec:Channel-SubSec:Buffered-Fig:Ex1}.
\begin{figure}[h!]
  \lstinputlisting{code/04-analyzer/non-read-message.txt}
  \caption{Beispielprogramm für nicht gelesenen Nachricht in gepuffertem Channel} 
  \label{Chap:Analyze-Sec:Channel-SubSec:Buffered-Fig:Ex1}
\end{figure}
Es besitzt 2 Send- aber nur eine Receive-Operation. Wäre der Channel nicht 
gepuffert, und hätte 1 mit 3 synchronisiert, würde 2 blockieren und es 
würde zu einem Deadlock, bzw. dadurch dass 2 nicht in der Main-Routine liegt
zu einer hängenden Operation kommen. Dadurch das der Channel allerdings gepuffert ist
können sowohl 1 als auch 2 senden ohne zu blockieren. Da der Trace somit ein gültiges Post-Event dieser Operation besitzt, 
wird dieses Problem nicht durch die in 
Abschnitt~\ref{Chap:Analyze-Sec:Channel-SubSec:Dangling} beschriebenen Methode erkannt.
Solche Situation lassen sich allerdings aus Trace einfach erkennen.
Dazu wird der mit Vector-Clocks annotierte Trace durchlaufen. Auf diesem 
wird nun für jeden Channel gezählt, wie oft erfolgreich gesendet bzw. erfolgreich empfangen 
wurde (Anzahl der entsprechenden Elemente, bei denen die Post-Vector-Clock 
nicht max(Int) ist). Ist die Anzahl der erfolgreichen Send größer als 
die Anzahl der erfolgreichen Receive, bedeutet diese, dass nach Abschluss des 
Programms auf dem entsprechenden Channel noch nicht gelesene Nachrichten vorhanden sind.\\\\
In dem Beispiel in Abb.~\ref{Chap:Analyze-Sec:Channel-SubSec:Dangling}
wird eine weitere Problematik mit gepufferten Channels deutlich. 
Betrachtet man nur die Vector-Clock Informationen, dann scheint es, als wären 
2 und 3 potenzielle Kommunikationspartner. Dies ist allerdings nicht der Fall. 
In Go sind gepufferte Channels als FIFO Queue implementiert~\cite{chan-impl}. 
Das bedeutet, dass bei einem Receive immer diejenige Nachricht ausgegeben wird, 
welche bereits am längsten in dem Puffer des Channels gehalten wird. Da 
1 in dem Beispiel immer vor 2 ausgeführt wird und demnach in 3 immer die 
Nachricht aus 1 empfangen wird, bilden 2 und 3 kein mögliches Kommunikationspaar
und sollte somit auch nicht als solches ausgegeben werden. Um solche Situationen 
zu erkennen, wird in dem Trace für jedes Post-Event gespeichert, die 
wievielte Send- bzw. Receive-Operation auf diesem Channel bereits erfolgreich 
ausgeführt worden sind. Bei der Suche nach möglichen Kommunikationspartnern 
wird nun für gepufferte Channels überprüft, ob die Anzahl der gesendeten 
Nachrichten in dem Send-Statement mit der Anzahl der empfangenen 
Nachrichten in dem Receive-Statement übereinstimmt. Da die 
Send- und Receive-Operation nicht gleichzeitig ausgeführt werden müssen, 
ist es nicht notwendig die Vector-Clocks zu betrachten.
\todo{Noch genauer beschreiben}

\section{Select}
In Go können Select-Statements dazu verwendet werden, abhängig davon, 
auf welchen Channels Nachrichten gesendet werden unterschiedliche Programmteile
auszuführen. Dies erschwert die Analyse des Programs, da der 
tatsächliche Programmablauf dabei praktisch non-deterministisch werden 
kann~\cite{select-spec}. Da der aufgezeichnete Trace immer nur einen 
Programmablauf widerspiegelt, führt dies zu Problemen, da 
nicht betrachtete Ausführungspfade zu Deadlocks oder anderen Problemen 
führen. Eine Möglichkeit besteht darin, das Programm mehrfach auszuführen, 
und dabei immer unterschiedliche Select-Cases zu erzwingen. Dies ist der Ansatz,
welcher für den GFuzz-Detektor~\cite{gfuzz} gewählt wurde. Dazu werden die 
Select-Statements in dem Programmcode so verändert, dass aus den vorhandenen 
Cases eines gezielt ausgewählt werden kann. Ein Beispiel dazu findet sich 
in Abb.~\ref{Chap:Analyze-Sec:Channel-SubSec:Select-Fig:GFuzz_Inst}.
\begin{figure}[h!]
  \begin{minipage}[t]{0.3\textwidth}
    \lstinputlisting[xrightmargin=-50pt]{code/04-analyzer/gfuzz-select-pre.txt}
  \end{minipage}
  \begin{minipage}[t]{0.65\textwidth}
    \lstinputlisting[xrightmargin=40pt]{code/04-analyzer/gfuzz-select-post.txt}
  \end{minipage}
  \caption{Beispiel für die Order-Enforcement-Instrumentierung eines Select-Statements 
  durch GFuzz for (links) und nach der Implementierung (rechts). Ersetze $......$
  in dem Programm nach der Instrumentierung (rechts) durch das Programm vor der 
  Instrumentierung (links).~\cite[gekürzt]{gfuzz}}
  \label{Chap:Analyze-Sec:Channel-SubSec:Select-Fig:GFuzz_Inst}
\end{figure}
Durch die Switch-Operation lässt sich einer der Fälle in der ursprünglichen 
Select-Operation auswählen, welche bevorzugt ausgeführt werden soll. Nur 
wenn dieser innerhalb einer voreingestellten Zeit nicht ausgeführt wird, 
wird die ursprüngliche Select-Operation vollständig ausgeführt um zu verhindern, 
dass es durch diese Instrumentierung zu einem Deadlock kommt, welche ohne 
sie nicht aufgetreten wäre. Der Ablauf eines Programms bezüglich seiner 
Select-Statements kann nun als Liste von Tupeln 
$[(s_0, c_0, e_0), \ldots, (s_n, c_n, e_n)]$ dargestellt werden. Dabei 
bezeichnet $s_i (0 \leq i \leq n)$ die ID einer Select-Operation, $c_i$ 
die Anzahl der Cases in dieser Operation und $e_n$ den Index des Ausgeführten 
Case. Das Programm wird nun mehrfach durchlaufen, wobei die Ordnung zufällig 
verändert wird. Dazu wird nach jedem Durchlauf der Index $e_i$ jedes Tupels 
auf einen zufälligen, aber gültigen Wert gesetzt. Da die Anzahl der möglichen 
Ausführungspfade durch die Select-Statements gegebenenfalls gegen unendlich gehen kann,
ist es nicht möglich jede mögliche Kombination von Select-Cases auszuführen.
Aus diesem Grund sammelt GFuzz während der Ausführung einer Ordnung Informationen 
über diese, um die Qualität einer Ordnung abzuschätzen. Aus diesen wird 
über 
\begin{align}
  \begin{split}
    score = &\sum_j \log_2{CountChOpPair_j} + 10 \cdot \# CreateCh \\
            &+ 10 \cdot \#CloseCh + 10 \cdot \sum_j MaxChBufFull_j
  \end{split}
\end{align}
eine Wertung für die durchlaufenden Ordnung bestimmt, über welche die 
Anzahl der Mutationen bestimmt werden. Hierbei bezeichnet $CountChOpPair_j$ 
die Anzahl der neuen Ausführungen von Channel-Operationen pro Channel $j$, $CreateCh$
die Anzahl der neu erzeugten Channels, $CloseCh$ die Anzahl der neu geschlossenen 
Channels und $MaxChBufFull_j$ die neue maximale Anzahl an 
gepufferten Nachrichten in jedem Channel $j$. Neu bedeutet hierbei, dass die
entsprechende Operation noch nicht, auch nicht in vorherigen Durchläufen, 
aufgetreten ist. Die Anzahl der Mutationen 
einer Ordnung gibt sich nun als $\# nuwMut = \lceil 5 \cdot \nicefrac{score}{maxScode} \rceil$, 
wobei $score$ den Score der Ordnung und $maxScore$ den bisher maximal 
erhaltenen Score bezeichnet. Diese $\# newMut$ neuen Mutationen werden nun 
basierend auf der alten erzeugt, in eine Queue eingefügt und anschließend 
durchlaufen. GFuzz beschränkt sich bei der Erkennung von Bugs auf die Erkennung
von blockenden Bugs.\\\\
Diese Betrachtung der verschiedenen Pfade soll nun auch für GoChan 
\todo{gegebenenfall umbenennen} verwendet werden. Für jeden Durchlauf wird 
ein Trace aufgezeichnet und dieser basierend 
auf~\ref{Chan:Analyze-Sec:Mutex} und~\ref{Chap:Analyse-Sec:Channel}
\todo{Gegenenenfalls anpassen}
analysiert.
\todo{cont, implementierung beschreiben}